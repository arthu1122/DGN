{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# 编码DRUG和TAR\n",
    "df_d = pd.read_csv(\"../data/raw/Feature_DRUG.csv\")\n",
    "df_t = pd.read_csv(\"../data/raw/Feature_TAR.csv\")\n",
    "\n",
    "drug_ids = df_d['DrugID']\n",
    "tar_ids = df_t['TargetID']\n",
    "\n",
    "drug_vocab = []\n",
    "for id in drug_ids:\n",
    "    drug_vocab.append(\"Drug|||\" + str(id) + \"\\n\")\n",
    "\n",
    "tar_vocab = []\n",
    "for id in tar_ids:\n",
    "    tar_vocab.append(\"Target|||\" + str(id) + \"\\n\")\n",
    "\n",
    "with open(\"../data/processed/drug_vocab.txt\", 'w') as file:\n",
    "    file.writelines(drug_vocab)\n",
    "\n",
    "with open(\"../data/processed/tar_vocab.txt\", 'w') as file:\n",
    "    file.writelines(tar_vocab)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "with open(\"../data/processed/drug_vocab.txt\", 'r') as file:\n",
    "    drug_vocab = file.readlines()\n",
    "\n",
    "with open(\"../data/processed/tar_vocab.txt\", 'r') as file:\n",
    "    tar_vocab = file.readlines()\n",
    "\n",
    "drug_id_dict = {}\n",
    "for i in range(len(drug_vocab)):\n",
    "    drug_id_dict[drug_vocab[i][:-1]] = i\n",
    "\n",
    "tar_id_dict = {}\n",
    "for i in range(len(tar_vocab)):\n",
    "    tar_id_dict[tar_vocab[i][:-1]] = i\n",
    "\n",
    "\n",
    "def get_id(ID, is_drug=True):\n",
    "    if is_drug:\n",
    "        key = \"Drug|||\" + str(ID)\n",
    "        return drug_id_dict[key]\n",
    "    else:\n",
    "        key = \"Target|||\" + str(ID)\n",
    "        return tar_id_dict[key]\n",
    "\n",
    "\n",
    "# drug_drug edge_index 和 edge_att\n",
    "edge_index = []\n",
    "edge_att = []\n",
    "e_dd = pd.read_csv(\"../data/raw/Edge_DRUG-DRUG.csv\", dtype='str')\n",
    "\n",
    "cols = e_dd.columns[1:]\n",
    "for index, row in e_dd.iterrows():\n",
    "    id = get_id(row['DrugID'])\n",
    "    for col in cols:\n",
    "        if str(row['DrugID']) == str(col):\n",
    "            continue\n",
    "        edge_index.append([id, get_id(col)])\n",
    "        edge_att.append(e_dd.loc[index, col])\n",
    "with open(\"../data/processed/drug_drug_edge_index.txt\", 'w') as file:\n",
    "    for e_i in edge_index:\n",
    "        file.write(str(e_i))\n",
    "        file.write(\"\\n\")\n",
    "\n",
    "with open(\"../data/processed/drug_drug_edge_att.txt\", 'w') as file:\n",
    "    for e_t in edge_att:\n",
    "        file.write(str(e_t))\n",
    "        file.write(\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "\n",
    "# target_target edge_index 和 edge_att\n",
    "edge_index = []\n",
    "edge_att = []\n",
    "e_dd = pd.read_csv(\"../data/raw/Edge_TAR-TAR.csv\", dtype='str')\n",
    "\n",
    "for index, row in e_dd.iterrows():\n",
    "    id1 = get_id(row['TargetID1'], False)\n",
    "    id2 = get_id(row['TargetID2'], False)\n",
    "\n",
    "    edge_index.append([id1, id2])\n",
    "    edge_att.append(1.0)\n",
    "\n",
    "with open(\"../data/processed/tar_tar_edge_index.txt\", 'w') as file:\n",
    "    for e_i in edge_index:\n",
    "        file.write(str(e_i))\n",
    "        file.write(\"\\n\")\n",
    "\n",
    "with open(\"../data/processed/tar_tar_edge_att.txt\", 'w') as file:\n",
    "    for e_t in edge_att:\n",
    "        file.write(str(e_t))\n",
    "        file.write(\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "\n",
    "# drug_target edge_index 和 edge_att\n",
    "edge_index = []\n",
    "edge_att = []\n",
    "e_dd = pd.read_csv(\"../data/raw/Edge_DRUG-TAR.csv\", dtype='str')\n",
    "\n",
    "for index, row in e_dd.iterrows():\n",
    "    id1 = get_id(row['DrugID'])\n",
    "    id2 = get_id(row['TargetID'], False)\n",
    "\n",
    "    edge_index.append([id1, id2])\n",
    "    edge_att.append(1.0)\n",
    "\n",
    "with open(\"../data/processed/drug_tar_edge_index.txt\", 'w') as file:\n",
    "    for e_i in edge_index:\n",
    "        file.write(str(e_i))\n",
    "        file.write(\"\\n\")\n",
    "\n",
    "with open(\"../data/processed/drug_tar_edge_att.txt\", 'w') as file:\n",
    "    for e_t in edge_att:\n",
    "        file.write(str(e_t))\n",
    "        file.write(\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# 数据集打乱\n",
    "df = pd.read_csv(\"../data/raw/Label_DRUGCOMB.csv\")\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "df = shuffle(df)\n",
    "df.to_csv(\"../data/processed/Shuffled_Label_Data.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# results.txt 转 csv\n",
    "txt_file = \"../data/result/GATNet(DrugA_DrugB)0--AUCs.txt\"\n",
    "with open(txt_file, 'r') as f:\n",
    "    texts = f.readlines()\n",
    "\n",
    "res = []\n",
    "for text in texts:\n",
    "    res.append(text[:-1].split('\\t'))\n",
    "\n",
    "df = pd.DataFrame(data=res)\n",
    "df.to_csv(\"../data/result/GATNet_results.csv\", header=0, index=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lenth 91155\n",
      "pot 18231\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# split to 5 folds\n",
    "\n",
    "df = pd.read_csv(\"../data/raw/Label_DRUGCOMB.csv\")\n",
    "\n",
    "lenth = len(df)\n",
    "pot = int(lenth / 5)\n",
    "print('lenth', lenth)\n",
    "print('pot', pot)\n",
    "random_num = random.sample(range(0, lenth), lenth)\n",
    "\n",
    "for i in range(5):\n",
    "    test_num = random_num[pot * i:pot * (i + 1)]\n",
    "    train_num = random_num[:pot * i] + random_num[pot * (i + 1):]\n",
    "    test_data = df.iloc[test_num]\n",
    "    train_data = df.iloc[train_num]\n",
    "    test_data.to_csv(\"../data/processed/fold_data/fold_\" + str(i + 1) + \"_test.csv\")\n",
    "    train_data.to_csv(\"../data/processed/fold_data/fold_\" + str(i + 1) + \"_train.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YuJie\\AppData\\Local\\Temp\\ipykernel_17172\\1268609829.py:23: RuntimeWarning: invalid value encountered in divide\n",
      "  X = (X - means2) / std2\n"
     ]
    }
   ],
   "source": [
    "# 标准化数据\n",
    "\n",
    "def normalize(X, means1=None, std1=None, means2=None, std2=None, feat_filt=None, norm='tanh_norm'):\n",
    "    if std1 is None:\n",
    "        std1 = np.nanstd(X, axis=0)\n",
    "    if feat_filt is None:\n",
    "        feat_filt = std1 != 0\n",
    "    X = X[:, feat_filt]\n",
    "    X = np.ascontiguousarray(X)\n",
    "    if means1 is None:\n",
    "        means1 = np.mean(X, axis=0)\n",
    "    X = (X - means1) / std1[feat_filt]\n",
    "    if norm == 'norm':\n",
    "        return X, (means1, std1, feat_filt)\n",
    "    elif norm == 'tanh':\n",
    "        return np.tanh(X), (means1, std1, feat_filt)\n",
    "    elif norm == 'tanh_norm':\n",
    "        X = np.tanh(X)\n",
    "        if means2 is None:\n",
    "            means2 = np.mean(X, axis=0)\n",
    "        if std2 is None:\n",
    "            std2 = np.std(X, axis=0)\n",
    "        X = (X - means2) / std2\n",
    "        X[:, std2 == 0] = 0\n",
    "        return X, (means1, std1, means2, std2, feat_filt)\n",
    "\n",
    "\n",
    "feature_cell = pd.read_csv(\"../data/raw/Feature_CELL.csv\")\n",
    "feature_tar = pd.read_csv(\"../data/raw/Feature_TAR.csv\")\n",
    "feature_drug = pd.read_csv(\"../data/raw/Feature_DRUG.csv\")\n",
    "\n",
    "cell = np.array(feature_cell.values)\n",
    "tar = np.array(feature_tar.values)\n",
    "drug = np.array(feature_drug.values)\n",
    "\n",
    "# [122,890]\n",
    "nor_cell, _ = normalize(cell[:, 1:].astype(float))\n",
    "# [61,570]\n",
    "nor_tar, _ = normalize(tar[:, 1:].astype(float))\n",
    "# [122,188]\n",
    "nor_drug, _ = normalize(drug[:, 1:].astype(float))\n",
    "\n",
    "# _cell=np.concatenate((cell[:,0],nor_cell),axis=0)\n",
    "# _tar=tar[:,0]+nor_tar\n",
    "# _drug=drug[:,0]+nor_drug\n",
    "\n",
    "cell_df = pd.DataFrame(nor_cell, index=feature_cell['Cell_Line_Name'])\n",
    "tar_df = pd.DataFrame(nor_tar, index=feature_tar['TargetID'])\n",
    "drug_df = pd.DataFrame(nor_drug, index=feature_drug['DrugID'])\n",
    "\n",
    "cell_df.to_csv(\"../data/processed/feature/Feature_CELL.csv\")\n",
    "tar_df.to_csv(\"../data/processed/feature/Feature_TAR.csv\")\n",
    "drug_df.to_csv(\"../data/processed/feature/Feature_DRUG.csv\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# 把cell feature 和 label_data 合在一起\n",
    "cells = pd.read_csv(\"../data/processed/feature/Feature_CELL.csv\", index_col='Cell_Line_Name', dtype=str)\n",
    "label_data = pd.read_csv(\"../data/raw/Label_DRUGCOMB.csv\")\n",
    "cell_list = list(label_data['Cell_Line_Name'].str.lower())\n",
    "\n",
    "cells.index = cells.index.str.lower()\n",
    "\n",
    "features_cell_np = cells.loc[cell_list].to_numpy().astype('float')\n",
    "\n",
    "label_data_np = label_data.to_numpy()\n",
    "final = np.concatenate((label_data_np, features_cell_np), axis=1)\n",
    "\n",
    "cell_col = [\"cell_feature_\" + str(x) for x in cells.columns]\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "new_col = list(label_data.columns)\n",
    "new_col.extend(cell_col)\n",
    "\n",
    "res = pd.DataFrame(final, columns=new_col)\n",
    "res.to_csv(\"../data/processed/all_data.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}